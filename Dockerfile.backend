FROM python:3.12

# Avoid interactive prompts
ENV DEBIAN_FRONTEND=noninteractive

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    git \
    curl \
    wget \
    lsof \
    vim \
    unzip \
    sqlite3 \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Install Poetry
RUN pip install poetry

# Configure Poetry not to create virtual environments (unnecessary in containers)
RUN poetry config virtualenvs.create false

# Copy dependency files first, leveraging Docker cache
COPY pyproject.toml poetry.lock* /app/
COPY README.md /app/
COPY dependencies/ /app/dependencies/

# Use Poetry to install dependencies
RUN poetry install --no-interaction --no-root

# Install specific version of graphrag
RUN GRAPHRAG_TARGET="1.2.1.dev27" && \
    GRAPHRAG_LOCAL_PATH="dependencies/graphrag-${GRAPHRAG_TARGET}.tar.gz" && \
    pip install --force-reinstall "$GRAPHRAG_LOCAL_PATH"

# Build llama.cpp
RUN set -e && \
    LLAMA_LOCAL_ZIP="dependencies/llama.cpp.zip" && \
    echo "Using local llama.cpp archive..." && \
    unzip -q "$LLAMA_LOCAL_ZIP" && \
    cd llama.cpp && \
    mkdir -p build && cd build && \
    cmake .. && \
    cmake --build . --config Release && \
    if [ ! -f "bin/llama-server" ]; then \
        echo "Build failed: llama-server executable not found" && \
        exit 1; \
    else \
        echo "Successfully built llama-server" && \
        cd ../..; \
    fi

# Copy backend files
COPY lpm_kernel/ /app/lpm_kernel/

# Copy initialization scripts
COPY docker/ /app/docker/

# Create necessary directories for data storage
RUN mkdir -p /app/data/sqlite \
    /app/data/chroma_db \
    /app/logs \
    /app/run \
    /app/resources

# Create initial database structure
RUN echo "Creating initial database structure..." && \
    mkdir -p /app/data/sqlite && \
    echo "Executing SQL file with .read command..." && \
    sqlite3 /app/data/sqlite/lpm.db ".read /app/docker/sqlite/init.sql" && \
    echo "Initial database created" && \
    \
    # Show SQL file content for debugging
    echo "First 10 lines of init.sql:" && \
    head -10 /app/docker/sqlite/init.sql && \
    \
    # Verify tables were created successfully
    echo "Verifying created tables..." && \
    TABLES=$(sqlite3 /app/data/sqlite/lpm.db ".tables") && \
    echo "Tables created: $TABLES" && \
    \
    # Check for specific tables
    echo "Checking for specific tables..." && \
    USER_CONFIG_COUNT=$(sqlite3 /app/data/sqlite/lpm.db "SELECT count(name) FROM sqlite_master WHERE type='table' AND name='user_llm_configs';") && \
    echo "user_llm_configs table exists: $USER_CONFIG_COUNT" && \
    \
    # Check for critical tables - use grep instead of [[ ]] for sh compatibility
    if ! echo "$TABLES" | grep -q "user_llm_configs"; then \
        echo "ERROR: Critical table 'user_llm_configs' was not created!" && \
        echo "Attempting to create table directly..." && \
        sqlite3 /app/data/sqlite/lpm.db "CREATE TABLE IF NOT EXISTS user_llm_configs (id INTEGER PRIMARY KEY AUTOINCREMENT, provider_type VARCHAR(50) NOT NULL DEFAULT 'openai', key VARCHAR(200), chat_endpoint VARCHAR(200), chat_api_key VARCHAR(200), chat_model_name VARCHAR(200), embedding_endpoint VARCHAR(200), embedding_api_key VARCHAR(200), embedding_model_name VARCHAR(200), created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP);" && \
        sqlite3 /app/data/sqlite/lpm.db "CREATE INDEX IF NOT EXISTS idx_user_llm_configs_created_at ON user_llm_configs(created_at);" && \
        \
        # Verify again after direct creation
        TABLES_AFTER=$(sqlite3 /app/data/sqlite/lpm.db ".tables") && \
        echo "Tables after direct creation: $TABLES_AFTER" && \
        \
        if ! echo "$TABLES_AFTER" | grep -q "user_llm_configs"; then \
            echo "ERROR: Still could not create user_llm_configs table!" && \
            exit 1; \
        else \
            echo "Successfully created user_llm_configs table manually."; \
        fi \
    elif ! echo "$TABLES" | grep -q "document"; then \
        echo "ERROR: Critical table 'document' was not created!" && \
        exit 1; \
    else \
        echo "Database initialization verified successfully"; \
    fi

# Initialize ChromaDB
RUN echo "Initializing ChromaDB..." && \
    python /app/docker/app/init_chroma.py && \
    echo "ChromaDB initialized"

# Set Python environment variables - all in one layer
ENV PYTHONUNBUFFERED=1 \
    PYTHONPATH=/app \
    BASE_DIR=/app/data \
    LOCAL_LOG_DIR=/app/logs \
    RUN_DIR=/app/run \
    RESOURCES_DIR=/app/resources \
    APP_ROOT=/app \
    FLASK_APP=lpm_kernel.app

# Test that the module can be imported
RUN python -c "import lpm_kernel; print('lpm_kernel module can be imported')"

# Expose backend port
EXPOSE 8002 8080

# Set the startup command
CMD bash -c 'echo "Starting application at $(date)" >> /app/logs/backend.log && \
             cd /app && \
             python -m flask run --host=0.0.0.0 --port=${LOCAL_APP_PORT:-8002} >> /app/logs/backend.log 2>&1'
