FROM python:3.12

# Set working directory
WORKDIR /app

# Install system dependencies, Poetry and configure it
RUN apt-get update && apt-get install -y \
    build-essential cmake git curl wget lsof vim unzip sqlite3 \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/* \
    && pip install --upgrade pip \
    && pip install poetry \
    && poetry config virtualenvs.create false

# Create directories
RUN mkdir -p /app/dependencies /app/data/sqlite /app/data/chroma_db /app/logs /app/run /app/resources

# Copy dependency files - Files that rarely change
COPY dependencies/graphrag-1.2.1.dev27.tar.gz /app/dependencies/
COPY dependencies/llama.cpp.zip /app/dependencies/

# Build llama.cpp with conditional CUDA support
RUN LLAMA_LOCAL_ZIP="dependencies/llama.cpp.zip" \
    && echo "Using local llama.cpp archive..." \
    && unzip -q "$LLAMA_LOCAL_ZIP" \
    && cd llama.cpp \
    && mkdir -p build && cd build \
    && if nvidia-smi &>/dev/null; then \
         echo "NVIDIA GPU detected, attempting to build with CUDA support..." && \
         # Look for CUDA libraries from Python packages \
         CUDA_RUNTIME=$(find /usr -name 'libcudart.so*' | head -1) && \
         if [ -n "$CUDA_RUNTIME" ]; then \
           CUDA_PATH=$(dirname $(dirname $CUDA_RUNTIME)) && \
           echo "Found CUDA runtime at: $CUDA_RUNTIME" && \
           echo "Setting CUDA_PATH to: $CUDA_PATH" && \
           # Use CMake to find CUDA components \
           CMAKE_OPTS="-DGGML_CUDA=ON -DCMAKE_PREFIX_PATH=$CUDA_PATH" && \
           echo "Building with CUDA support using options: $CMAKE_OPTS" && \
           cmake $CMAKE_OPTS .. ; \
         else \
           echo "CUDA runtime libraries not found, building without GPU support" && \
           cmake .. ; \
         fi; \
       else \
         echo "No NVIDIA GPU detected, building without CUDA support" && \
         cmake .. ; \
       fi \
    && cmake --build . --config Release -j \
    && if [ ! -f "bin/llama-server" ]; then \
         echo "Build failed: llama-server executable not found" && exit 1; \
       else \
         echo "Successfully built llama-server"; \
       fi \
    && chmod +x bin/llama-server bin/llama-cli

# Copy project configuration - Files that occasionally change
COPY pyproject.toml README.md /app/

RUN poetry install --no-interaction --no-root
RUN pip install --force-reinstall dependencies/graphrag-1.2.1.dev27.tar.gz

# Copy source code - Files that frequently change
COPY docker/ /app/docker/
COPY lpm_kernel/ /app/lpm_kernel/

# Make the CUDA rebuild script executable
RUN chmod +x /app/docker/app/rebuild_llama_cuda.sh

# Check module import
RUN python -c "import lpm_kernel; print('Module import check passed')"

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    PYTHONPATH=/app \
    BASE_DIR=/app/data \
    LOCAL_LOG_DIR=/app/logs \
    RUN_DIR=/app/run \
    RESOURCES_DIR=/app/resources \
    APP_ROOT=/app \
    FLASK_APP=lpm_kernel.app

# Expose ports
EXPOSE 8002 8080

# Set the startup command
CMD ["bash", "-c", "echo \"Checking llama.cpp CUDA support at runtime...\" && /app/docker/app/ensure_cuda_support.sh && echo \"Checking SQLite database...\" && if [ ! -s /app/data/sqlite/lpm.db ]; then echo \"SQLite database not found or empty, initializing...\" && mkdir -p /app/data/sqlite && sqlite3 /app/data/sqlite/lpm.db \".read /app/docker/sqlite/init.sql\" && echo \"SQLite database initialized successfully\" && echo \"Tables created:\" && sqlite3 /app/data/sqlite/lpm.db \".tables\"; else echo \"SQLite database already exists, skipping initialization\"; fi && echo \"Checking ChromaDB...\" && if [ ! -d /app/data/chroma_db/documents ] || [ ! -d /app/data/chroma_db/document_chunks ]; then echo \"ChromaDB collections not found, initializing...\" && python /app/docker/app/init_chroma.py && echo \"ChromaDB initialized successfully\"; else echo \"ChromaDB already exists, skipping initialization\"; fi && echo \"Starting application at $(date)\" >> /app/logs/backend.log && cd /app && python -m flask run --host=0.0.0.0 --port=${LOCAL_APP_PORT:-8002} >> /app/logs/backend.log 2>&1"]
