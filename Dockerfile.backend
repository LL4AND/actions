FROM python:3.12

# Avoid interactive prompts
ENV DEBIAN_FRONTEND=noninteractive

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    git \
    curl \
    wget \
    lsof \
    vim \
    unzip \
    sqlite3 \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Install Poetry
RUN pip install poetry

# Configure Poetry not to create virtual environments (unnecessary in containers)
RUN poetry config virtualenvs.create false

# Copy dependency files first, leveraging Docker cache
COPY pyproject.toml poetry.lock* /app/
COPY README.md /app/
COPY dependencies/ /app/dependencies/

# Use Poetry to install dependencies
RUN poetry install --no-interaction --no-root

# Install specific version of graphrag
RUN GRAPHRAG_TARGET="1.2.1.dev27" && \
    GRAPHRAG_LOCAL_PATH="dependencies/graphrag-${GRAPHRAG_TARGET}.tar.gz" && \
    if [ -f "$GRAPHRAG_LOCAL_PATH" ]; then \
        pip install --force-reinstall "$GRAPHRAG_LOCAL_PATH"; \
    else \
        echo "Warning: graphrag package not found at $GRAPHRAG_LOCAL_PATH"; \
    fi

# Build llama.cpp
RUN set -e && \
    LLAMA_LOCAL_ZIP="dependencies/llama.cpp.zip" && \
    echo "Using local llama.cpp archive..." && \
    unzip -q "$LLAMA_LOCAL_ZIP" && \
    cd llama.cpp && \
    mkdir -p build && cd build && \
    cmake .. && \
    cmake --build . --config Release && \
    if [ ! -f "bin/llama-server" ]; then \
        echo "Build failed: llama-server executable not found" && \
        exit 1; \
    else \
        echo "Successfully built llama-server" && \
        cd ../..; \
    fi

# Copy backend files
COPY lpm_kernel/ /app/lpm_kernel/

# Copy initialization scripts
COPY docker/ /app/docker/

# Create necessary directories for data storage
RUN mkdir -p /app/data/sqlite \
    /app/data/chroma_db \
    /app/logs \
    /app/run \
    /app/resources

# Create initial database structure (will be overridden by mounted volume)
RUN echo "Creating initial database structure..." && \
    if [ -f "/app/docker/sqlite/init.sql" ]; then \
        mkdir -p /app/data/sqlite && \
        cat /app/docker/sqlite/init.sql | sqlite3 /app/data/sqlite/lpm.db && \
        echo "Initial database created"; \
    else \
        echo "Warning: init.sql not found, skipping database initialization"; \
    fi

# Initialize ChromaDB (will be overridden by mounted volume)
RUN echo "Initializing ChromaDB..." && \
    if [ -f "/app/docker/app/init_chroma.py" ]; then \
        python /app/docker/app/init_chroma.py && \
        echo "ChromaDB initialized"; \
    else \
        echo "Warning: init_chroma.py not found, skipping ChromaDB initialization"; \
    fi

# Set Python environment
ENV PYTHONUNBUFFERED=1
ENV PYTHONPATH=/app
ENV BASE_DIR=/app/data
ENV LOCAL_LOG_DIR=/app/logs
ENV RUN_DIR=/app/run
ENV RESOURCES_DIR=/app/resources
ENV APP_ROOT=/app
ENV FLASK_APP=lpm_kernel.app

# Test that the module can be imported
RUN python -c "import lpm_kernel; print('lpm_kernel module can be imported')"

# Expose backend port
EXPOSE 8002
EXPOSE 8080

# Set the startup command
CMD bash -c 'echo "Starting application at $(date)" >> /app/logs/backend.log && \
             cd /app && \
             python -m flask run --host=0.0.0.0 --port=${LOCAL_APP_PORT:-8002} >> /app/logs/backend.log 2>&1'
